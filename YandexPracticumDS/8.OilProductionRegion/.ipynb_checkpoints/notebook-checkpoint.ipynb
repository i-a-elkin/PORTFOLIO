{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4725588",
   "metadata": {},
   "source": [
    "# Выбор локации для скважины"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30cca33-02c5-406a-86da-c863336790d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Допустим, вы работаете в добывающей компании «ГлавРосГосНефть». Нужно решить, где бурить новую скважину.\n",
    "\n",
    "Вам предоставлены пробы нефти в трёх регионах: в каждом 10 000 месторождений, где измерили качество нефти и объём её запасов. Постройте модель машинного обучения, которая поможет определить регион, где добыча принесёт наибольшую прибыль. Проанализируйте возможную прибыль и риски техникой *Bootstrap.*\n",
    "\n",
    "**Шаги для выбора локации:**\n",
    "- В избранном регионе ищут месторождения, для каждого определяют значения признаков;\n",
    "- Строят модель и оценивают объём запасов;\n",
    "- Выбирают месторождения с самым высокими оценками значений. Количество месторождений зависит от бюджета компании и стоимости разработки одной скважины;\n",
    "- Прибыль равна суммарной прибыли отобранных месторождений.\n",
    "\n",
    "**Условия задачи:**\n",
    "- Для обучения модели подходит только линейная регрессия (остальные — недостаточно предсказуемые).\n",
    "- При разведке региона исследуют 500 точек, из которых с помощью машинного обучения выбирают 200 лучших для разработки.\n",
    "- Бюджет на разработку скважин в регионе — 10 млрд рублей.\n",
    "- При нынешних ценах один баррель сырья приносит 450 рублей дохода. Доход с каждой единицы продукта составляет 450 тыс. рублей, поскольку объём указан в тысячах баррелей.\n",
    "- После оценки рисков нужно оставить лишь те регионы, в которых вероятность убытков меньше 2.5%. Среди них выбирают регион с наибольшей средней прибылью.\n",
    "\n",
    "**Описание данных:**\n",
    "- id — уникальный идентификатор скважины;\n",
    "- f0, f1, f2 — три признака точек;\n",
    "- product — объём запасов в скважине (тыс. баррелей)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ec30b",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590e355e-bc55-41fe-9212-db1497f06232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a81b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from joblib import dump, load\n",
    "import sweetviz as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7be84b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Регион geo_data_0\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v1+json": {
       "is_truncated": false,
       "table": {
        "data": [
         {
          "f0": 0.7057449842,
          "f1": -0.4978225002,
          "f2": 1.2211699484,
          "id": "txEyH",
          "index": 0,
          "product": 105.2800618435
         },
         {
          "f0": 1.3347112926,
          "f1": -0.3401642529,
          "f2": 4.3650803324,
          "id": "2acmU",
          "index": 1,
          "product": 73.0377502652
         },
         {
          "f0": 1.0227322635,
          "f1": 0.1519904446,
          "f2": 1.4199262387,
          "id": "409Wp",
          "index": 2,
          "product": 85.265647131
         }
        ],
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "id",
           "type": "string"
          },
          {
           "name": "f0",
           "type": "number"
          },
          {
           "name": "f1",
           "type": "number"
          },
          {
           "name": "f2",
           "type": "number"
          },
          {
           "name": "product",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 3
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txEyH</td>\n",
       "      <td>0.705745</td>\n",
       "      <td>-0.497823</td>\n",
       "      <td>1.221170</td>\n",
       "      <td>105.280062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2acmU</td>\n",
       "      <td>1.334711</td>\n",
       "      <td>-0.340164</td>\n",
       "      <td>4.365080</td>\n",
       "      <td>73.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409Wp</td>\n",
       "      <td>1.022732</td>\n",
       "      <td>0.151990</td>\n",
       "      <td>1.419926</td>\n",
       "      <td>85.265647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2     product\n",
       "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
       "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
       "2  409Wp  1.022732  0.151990  1.419926   85.265647"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов 0, пропущенных значений 0\n",
      "Регион geo_data_1\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v1+json": {
       "is_truncated": false,
       "table": {
        "data": [
         {
          "f0": -15.0013481825,
          "f1": -8.2759999472,
          "f2": -0.0058760137,
          "id": "kBEdx",
          "index": 0,
          "product": 3.1791025832
         },
         {
          "f0": 14.272087811,
          "f1": -3.4750832151,
          "f2": 0.9991827366,
          "id": "62mP7",
          "index": 1,
          "product": 26.9532610315
         },
         {
          "f0": 6.2631873524,
          "f1": -5.9483857883,
          "f2": 5.0011601608,
          "id": "vyE1P",
          "index": 2,
          "product": 134.7663051577
         }
        ],
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "id",
           "type": "string"
          },
          {
           "name": "f0",
           "type": "number"
          },
          {
           "name": "f1",
           "type": "number"
          },
          {
           "name": "f2",
           "type": "number"
          },
          {
           "name": "product",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 3
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kBEdx</td>\n",
       "      <td>-15.001348</td>\n",
       "      <td>-8.276000</td>\n",
       "      <td>-0.005876</td>\n",
       "      <td>3.179103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62mP7</td>\n",
       "      <td>14.272088</td>\n",
       "      <td>-3.475083</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>26.953261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vyE1P</td>\n",
       "      <td>6.263187</td>\n",
       "      <td>-5.948386</td>\n",
       "      <td>5.001160</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         f0        f1        f2     product\n",
       "0  kBEdx -15.001348 -8.276000 -0.005876    3.179103\n",
       "1  62mP7  14.272088 -3.475083  0.999183   26.953261\n",
       "2  vyE1P   6.263187 -5.948386  5.001160  134.766305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов 0, пропущенных значений 0\n",
      "Регион geo_data_2\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v1+json": {
       "is_truncated": false,
       "table": {
        "data": [
         {
          "f0": -1.1469870984,
          "f1": 0.9633279217,
          "f2": -0.8289649222,
          "id": "fwXo0",
          "index": 0,
          "product": 27.7586732307
         },
         {
          "f0": 0.2627779017,
          "f1": 0.2698389573,
          "f2": -2.5301865155,
          "id": "WJtFt",
          "index": 1,
          "product": 56.0696966324
         },
         {
          "f0": 0.1945872817,
          "f1": 0.2890350018,
          "f2": -5.5864327709,
          "id": "ovLUW",
          "index": 2,
          "product": 62.8719100476
         }
        ],
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "id",
           "type": "string"
          },
          {
           "name": "f0",
           "type": "number"
          },
          {
           "name": "f1",
           "type": "number"
          },
          {
           "name": "f2",
           "type": "number"
          },
          {
           "name": "product",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 3
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fwXo0</td>\n",
       "      <td>-1.146987</td>\n",
       "      <td>0.963328</td>\n",
       "      <td>-0.828965</td>\n",
       "      <td>27.758673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WJtFt</td>\n",
       "      <td>0.262778</td>\n",
       "      <td>0.269839</td>\n",
       "      <td>-2.530187</td>\n",
       "      <td>56.069697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ovLUW</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>-5.586433</td>\n",
       "      <td>62.871910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2    product\n",
       "0  fwXo0 -1.146987  0.963328 -0.828965  27.758673\n",
       "1  WJtFt  0.262778  0.269839 -2.530187  56.069697\n",
       "2  ovLUW  0.194587  0.289035 -5.586433  62.871910"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов 0, пропущенных значений 0\n"
     ]
    }
   ],
   "source": [
    "# загрузим данные\n",
    "geo_data_0 = pd.read_csv('datasets/geo_data_0.csv')\n",
    "geo_data_1 = pd.read_csv('datasets/geo_data_1.csv')\n",
    "geo_data_2 = pd.read_csv('datasets/geo_data_2.csv')\n",
    "\n",
    "for data, name in zip([geo_data_0, geo_data_1, geo_data_2], \n",
    "                [\"geo_data_0\", \"geo_data_1\", \"geo_data_2\"]):\n",
    "    print(\"Регион {}\".format(name))\n",
    "    display(data.head(3))\n",
    "    print(\"Количество дубликатов {}, пропущенных значений {}\"\n",
    "         .format(data.duplicated().sum(), data.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d36208-07d4-474e-bcb2-51dbcbc45bb6",
   "metadata": {},
   "source": [
    "- Проведем исследовательский анализ данных с помощью пакета sweetviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd8282-cac7-4a85-9c66-c56e07024e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_0 = sv.analyze([geo_data_0[[\"f0\", \"f1\", \"f2\", \"product\"]], \"geo_data_0\"], target_feat=\"product\")\n",
    "report_0.show_html(\"sweetviz/geo_data_0.html\")\n",
    "report_0.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee35f7-b1ff-4fa9-92d4-42b88cac758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_1 = sv.analyze([geo_data_1[[\"f0\", \"f1\", \"f2\", \"product\"]], \"geo_data_1\"], target_feat=\"product\")\n",
    "report_1.show_html(\"sweetviz/geo_data_1.html\")\n",
    "report_1.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44e4ba-34fd-404e-a235-b767bbce4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_2 = sv.analyze([geo_data_2[[\"f0\", \"f1\", \"f2\", \"product\"]], \"geo_data_2\"], target_feat=\"product\")\n",
    "report_2.show_html(\"sweetviz/geo_data_2.html\")\n",
    "report_2.show_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd778c3-dd8f-4bbf-84aa-1761d19d5031",
   "metadata": {},
   "source": [
    "Исследуемые данные обладают следующими особенностями:\n",
    "- не наблюдается пропущенных значений, дубликатов и выбросов; \n",
    "- распределение целевого признака (запас сырья) в регионах 0 и 2 близко к нормальному, а в регионе 1 больше соответствует равномерному, но с увеличенным содержанием скважин с минимальным и максимальным запасом сырья;\n",
    "- в регионе 0 целевой признак коррелирует со всеми 3 признаками (f0, f1, f2) и имеет наибольшую корреляцию с f2;\n",
    "- в регионах 1 и 2 целевой признак коррелируе главным образов с признаком f2 и намного слабее с остальными, причем в регионе 1 данная корреляция является очень сильной, в в регионе 2 находится на среднем уровне."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad54e1",
   "metadata": {},
   "source": [
    "## Обучение и проверка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0d83d-5066-4d9c-bc59-969b53a11262",
   "metadata": {},
   "source": [
    "- Разобъем данные для каждого региона на обущающую и валидационную выборку в соотношении 75/25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaff76f-07d1-49ad-8bfe-374c58891700",
   "metadata": {},
   "source": [
    "Создадим функцию, которая разбивает данные на необходимые для анализа признаки, и целевой признак, после чего делит их на обучающую и валидационную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa1175e9-4446-4718-a4ae-22f58370c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(geo_data, features_drop=[\"id\", \"product\"], target=\"product\",\n",
    "                  test_size=.25, random_state=12345):\n",
    "    \"\"\"\n",
    "    Функция принимает на вход датафрейм с геоданными.\n",
    "    Делит его на признаки (f0, f1, f2) и целевой признак (product), \n",
    "    после этого разделяет на обучающую и валидационную выборки в соотношении 75/25.\n",
    "    На выходе выдает словарь с признаками и целевым признаком получившихся выборок.\n",
    "    \"\"\"\n",
    "    features = geo_data.drop(features_drop, axis=1)\n",
    "    target = geo_data[target]\n",
    "    \n",
    "    features_train, features_valid, target_train, target_valid = \\\n",
    "                    train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return {\"features_train\": features_train, \"target_train\": target_train, \n",
    "            \"features_valid\": features_valid, \"target_valid\": target_valid}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6081f92-444d-485b-b541-53e48d988054",
   "metadata": {},
   "source": [
    "Проверим работу функции и разобъем наши геоданные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e528436-dc8b-4a0c-ba86-5810a8f372d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датафрейм geo_data_0         \n",
      "Размеры обучающей выборки: features(75000, 3), target(75000,)         \n",
      "Размеры валидационной выборки: features(25000, 3), target(25000,)\n",
      " \n",
      "Датафрейм geo_data_1         \n",
      "Размеры обучающей выборки: features(75000, 3), target(75000,)         \n",
      "Размеры валидационной выборки: features(25000, 3), target(25000,)\n",
      " \n",
      "Датафрейм geo_data_2         \n",
      "Размеры обучающей выборки: features(75000, 3), target(75000,)         \n",
      "Размеры валидационной выборки: features(25000, 3), target(25000,)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for data, name in zip([geo_data_0, geo_data_1, geo_data_2], \n",
    "                      [\"geo_data_0\", \"geo_data_1\", \"geo_data_2\"]):\n",
    "    print(\"Датафрейм {}\\\n",
    "         \\nРазмеры обучающей выборки: features{}, target{}\\\n",
    "         \\nРазмеры валидационной выборки: features{}, target{}\\n{}\"\n",
    "         .format(name,\n",
    "                 data_split(data)[\"features_train\"].shape,\n",
    "                 data_split(data)[\"target_train\"].shape,\n",
    "                 data_split(data)[\"features_valid\"].shape,\n",
    "                 data_split(data)[\"target_valid\"].shape,\n",
    "                 \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91dd64e-d749-48d2-98d0-d89472d32095",
   "metadata": {},
   "source": [
    "Выборки разделились в нужной нам пропорции.\n",
    "\n",
    "Найдем модели машинного обучения с наименьшим значением RMSE для валидационной выборки каждого региона. Будем исследовать разные типы линейных моделей:\n",
    "- стандартную линейную регрессию (LinearRegression)\n",
    "- линейную регрессию с L2-регуляризацией (Ridge)\n",
    "- линейную регрессию с L1-регуляризацией (Lasso)\n",
    "\n",
    "Полученное значение RMSE должно быть меньше значения найденного с использованием предсказаний средним значением целевого признака валидационной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6242ba6f-3600-4fa1-97b9-f7b055ea694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_search(name, features_train, target_train,\n",
    "                       features_valid, target_valid):\n",
    "    \"\"\"\n",
    "    Функция принимает на вход название под которым будет сохранена модель, \n",
    "    наборы признаков (features, target) обучающей и валидационной выборок.\n",
    "    Последовательно перебирает модели линейной регрессии и \n",
    "    ищет среди них ту, при которой достигается минимальное \n",
    "    значение RMSE на валидационной выборке.\n",
    "    Сохраняет найденную модель в файл.\n",
    "    \"\"\"\n",
    "    best_model = None\n",
    "    best_rmse = mean_squared_error(target_valid, \n",
    "                                   [target_valid.mean()] * len(target_valid), \n",
    "                                   squared=False)\n",
    "    model = LinearRegression()\n",
    "    model.fit(features_train, target_train)\n",
    "    predict = model.predict(features_valid)\n",
    "    rmse = mean_squared_error(target_valid, predict, squared=False)\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model = model\n",
    "    \n",
    "    for i in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "        model_ridge = Ridge(alpha=i, max_iter=100000)\n",
    "        model_ridge.fit(features_train, target_train)\n",
    "        predict_ridge = model_ridge.predict(features_valid)\n",
    "        rmse_ridge = mean_squared_error(target_valid, predict_ridge, squared=False)\n",
    "        if rmse_ridge < best_rmse:\n",
    "            best_rmse = rmse_ridge\n",
    "            best_model = model_ridge\n",
    "    \n",
    "    for j in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "        model_lasso = Lasso(alpha=j, max_iter=100000)\n",
    "        model_lasso.fit(features_train, target_train)\n",
    "        predict_lasso = model_lasso.predict(features_valid)\n",
    "        rmse_lasso = mean_squared_error(target_valid, predict_lasso, squared=False)\n",
    "        if rmse_lasso < best_rmse:\n",
    "            best_rmse = rmse_lasso\n",
    "            best_model = model_lasso\n",
    "    \n",
    "    if best_model:\n",
    "        # сохраним в файл последнюю найденную модель    \n",
    "        dump(best_model, \"models/\" + name + \".joblib\")\n",
    "        print(\"Модель \" + name + \" сохранена:\" + \"\\n\" + \n",
    "              \"models/\" + name + \".joblib\")\n",
    "        # очистим последнюю найденную модель    \n",
    "        best_model = None\n",
    "    else:\n",
    "        print(\"Адекватная модель \" + name + \" не найдена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b761f-1289-47a1-a905-e14c02d8397b",
   "metadata": {},
   "source": [
    "- Найдем модели с наименьшим значением RMSE для наших выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78ccf225-2d68-49d7-8269-d6cd079d3a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель geo_data_0 сохранена:\n",
      "models/geo_data_0.joblib\n",
      "Модель geo_data_1 сохранена:\n",
      "models/geo_data_1.joblib\n",
      "Модель geo_data_2 сохранена:\n",
      "models/geo_data_2.joblib\n"
     ]
    }
   ],
   "source": [
    "for data, name in zip([geo_data_0, geo_data_1, geo_data_2], \n",
    "                      [\"geo_data_0\", \"geo_data_1\", \"geo_data_2\"]):\n",
    "    \n",
    "    model_search(name, data_split(data)[\"features_train\"],\n",
    "                       data_split(data)[\"target_train\"],\n",
    "                       data_split(data)[\"features_valid\"],\n",
    "                       data_split(data)[\"target_valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7975fa-709a-4bc2-a412-88e91bb0a265",
   "metadata": {},
   "source": [
    "Выведем на экран параметры найденных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19982a74-b50e-4d56-aaaf-2c2c8a4261c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель geo_data_0\n",
      "Lasso(alpha=0.0001, max_iter=100000)\n",
      "Коэффициенты модели:\n",
      "[3.593, -14.097, 6.593]\n",
      " \n",
      "Модель geo_data_1\n",
      "Lasso(alpha=0.0001, max_iter=100000)\n",
      "Коэффициенты модели:\n",
      "[-0.145, -0.022, 26.951]\n",
      " \n",
      "Модель geo_data_2\n",
      "Lasso(alpha=0.1, max_iter=100000)\n",
      "Коэффициенты модели:\n",
      "[0.0, -0.009, 5.7]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for model, name in zip([load(\"models/geo_data_0.joblib\"), \n",
    "                        load(\"models/geo_data_1.joblib\"), \n",
    "                        load(\"models/geo_data_2.joblib\")],\n",
    "                       [\"geo_data_0\", \"geo_data_1\", \"geo_data_2\"]):\n",
    "    \n",
    "    print(\"Модель {}\\n{}\\nКоэффициенты модели:\\n{}\\n{}\"\n",
    "          .format(name, \n",
    "                  model, \n",
    "                  list(np.round(model.coef_, 3)), \n",
    "                  \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767b3c2-e006-48b0-b8e7-f4119c5c54d9",
   "metadata": {},
   "source": [
    "Для всех трех регионов минимум RMSE достигается при использовании L1-регуляризации (штрафуется сумма абсолютных значений коэффициентов). Кроме этого можно видеть как изменяется влияние коэффициентов на предсказания модели от региона к региону. В регионах 1 и 2 повышется влияние коэффициента f2 и снижается влияние коэффициентов f0, f1 по сравнению с нулевым регионом. В регионе 2 коэффициент модели f0 перестает оказывать влияние на предсказания, ключевым становится коэффициент f2. Полученная закономерность может говорить о существенном отличии между регионами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541482f-58bb-4ddc-ac1c-10389a62cd62",
   "metadata": {},
   "source": [
    "Выведем на экран величины RMSE для полученных моделей, сравним их с ошибкой, получаемой при прогнозировании с помощью средних значений. Вначале создадим функцию для расчета RMSE и среднего запаса предсказанного сырья на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f05af23b-2e5b-4b57-a47e-09edeca0e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_calc(data, name, scale=False):\n",
    "    \"\"\"\n",
    "    Функция принимает на вход датафрейм с геоданными, \n",
    "    название сохраненной модели, и условие масштабирования.\n",
    "    Делит датафрейм с помощью функции data_split() или data_scale(),\n",
    "    в зависимости от условия, и выбирает\n",
    "    признаки и целевой признак валидационной выборки.\n",
    "    Выводит словарь, содержащий RMSE и среднее  \n",
    "    предсказанных значений.\n",
    "    \"\"\"\n",
    "    if not scale:\n",
    "        features_valid = data_split(data)[\"features_valid\"]\n",
    "        target_valid = data_split(data)[\"target_valid\"]\n",
    "        predict = load(\"models/\" + name + \".joblib\").predict(features_valid)\n",
    "        rmse = mean_squared_error(target_valid, predict, squared=False)\n",
    "    else:\n",
    "        features_valid = data_scale(data)[\"features_valid\"]\n",
    "        target_valid = data_scale(data)[\"target_valid\"]\n",
    "        predict = load(\"models/\" + name + \".joblib\").predict(features_valid)\n",
    "        rmse = mean_squared_error(target_valid, predict, squared=False)\n",
    "    \n",
    "    return {\"rmse\": rmse,\n",
    "           \"mean_predict\": np.mean(predict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c832e4-df5e-4814-8b7a-80904f4d07cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель geo_data_0         \n",
      "RMSE модели на валидационной выборке: 37.579421         \n",
      "Средний запас предсказанного сырья: 92.592570         \n",
      " \n",
      "Модель geo_data_1         \n",
      "RMSE модели на валидационной выборке: 0.893099         \n",
      "Средний запас предсказанного сырья: 68.728547         \n",
      " \n",
      "Модель geo_data_2         \n",
      "RMSE модели на валидационной выборке: 40.029371         \n",
      "Средний запас предсказанного сырья: 94.965856         \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for data, name in zip([geo_data_0, geo_data_1, geo_data_2], \n",
    "                      [\"geo_data_0\", \"geo_data_1\", \"geo_data_2\"]):\n",
    "    \n",
    "    print(\"Модель {}\\\n",
    "         \\nRMSE модели на валидационной выборке: {:.6f}\\\n",
    "         \\nСредний запас предсказанного сырья: {:.6f}\\\n",
    "         \\n{}\".\n",
    "         format(name,\n",
    "                rmse_calc(data, name)[\"rmse\"],\n",
    "                rmse_calc(data, name)[\"mean_predict\"],\n",
    "                \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef23c75-76e6-4d9f-9b75-eb0bca67d747",
   "metadata": {},
   "source": [
    "Сравним RMSE моделей с ошибкой предсказания, полученной с помощью средних значений целевого признака на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aba0f29-cf03-49b8-a459-74e45e56efcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка модели geo_data_0 на адекватность         \n",
      "RMSE с использованием среднего значения         \n",
      "целевого признака на валидационной выборке: 44.29         \n",
      "Средний запас сырья на валидационной выборке: 92.08         \n",
      " \n",
      "Проверка модели geo_data_1 на адекватность         \n",
      "RMSE с использованием среднего значения         \n",
      "целевого признака на валидационной выборке: 46.02         \n",
      "Средний запас сырья на валидационной выборке: 68.72         \n",
      " \n",
      "Проверка модели geo_data_2 на адекватность         \n",
      "RMSE с использованием среднего значения         \n",
      "целевого признака на валидационной выборке: 44.90         \n",
      "Средний запас сырья на валидационной выборке: 94.88         \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for data, name in zip([geo_data_0, geo_data_1, geo_data_2], \n",
    "                      [\"geo_data_0\", \"geo_data_1\", \"geo_data_2\"]):\n",
    "\n",
    "    target_valid = data_split(data)[\"target_valid\"]\n",
    "    adequacy_rmse = mean_squared_error(target_valid, \n",
    "                                       [target_valid.mean()] * len(target_valid), \n",
    "                                       squared=False)\n",
    "    \n",
    "    print(\"Проверка модели {} на адекватность\\\n",
    "         \\nRMSE с использованием среднего значения\\\n",
    "         \\nцелевого признака на валидационной выборке: {:.2f}\\\n",
    "         \\nСредний запас сырья на валидационной выборке: {:.2f}\\\n",
    "         \\n{}\".\n",
    "         format(name,\n",
    "                adequacy_rmse,\n",
    "                np.mean(target_valid),\n",
    "                \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d7e3a-5e7e-440d-9ce1-327662c0ff18",
   "metadata": {},
   "source": [
    "Можно видеть, что найденные модели (за исключением geo_data_1) имеют показатель RMSE близкий к тому, который можно получить с использованием среднего значения на валидационной выборке. Также можно видеть, что найденные модели довольно точно предсказывают средний запас сырья.\n",
    "\n",
    "Попробуем улучшить качество моделей с помощью масштабирования признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c2e34-f9d7-4ce7-b317-5c78b3654823",
   "metadata": {},
   "source": [
    "- Создадим копии выборок, содержащих признаки и приведем их к одному масштабу для дальнейших экспериментов с моделями машинного обучения. Для этого создадим функцию для масштабирования признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab58073b-fa83-458e-946a-a08cacf519df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scale(data):\n",
    "    \"\"\"\n",
    "    Функция принимает на вход датасет с информацией о месторождениях.\n",
    "    Делит его с помощью функции data_split(), создает копии обучающей и \n",
    "    валидационной выборок. После этого масштабирует признаки с \n",
    "    использованием StandardScaler(), целевой признак оставляет без\n",
    "    изменения.\n",
    "    Выводит словарь со значениями признаков после масштабирования и\n",
    "    целевого признака без изменения.\n",
    "    \"\"\"\n",
    "    numeric = [\"f0\", \"f1\", \"f2\"]\n",
    "    features_train_scale = data_split(data)[\"features_train\"].copy()\n",
    "    target_train_scale = data_split(data)[\"target_train\"].copy()\n",
    "    features_valid_scale = data_split(data)[\"features_valid\"].copy()\n",
    "    target_valid_scale = data_split(data)[\"target_valid\"].copy()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(features_train_scale[numeric])\n",
    "    \n",
    "    features_train_scale[numeric] = scaler.transform(features_train_scale[numeric])\n",
    "    features_valid_scale[numeric] = scaler.transform(features_valid_scale[numeric])\n",
    "    \n",
    "    return {\"features_train\": features_train_scale,\n",
    "            \"target_train\": target_train_scale,\n",
    "            \"features_valid\": features_valid_scale,\n",
    "            \"target_valid\": target_valid_scale}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74833953-2d39-41a0-924b-f5bced02b27b",
   "metadata": {},
   "source": [
    "Проверим работу функции. Выведем на экран данные geo_data_0 до и после масштабирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "591dcb46-553f-48df-b87d-03059dcf8143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выборка features_train до масштабирования\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v1+json": {
       "is_truncated": false,
       "table": {
        "data": [
         {
          "f0": 0.0224495763,
          "f1": 0.9510341066,
          "f2": 2.1973325222,
          "index": 27212
         },
         {
          "f0": 1.7667314126,
          "f1": 0.0078354639,
          "f2": 6.4366015619,
          "index": 7866
         }
        ],
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "f0",
           "type": "number"
          },
          {
           "name": "f1",
           "type": "number"
          },
          {
           "name": "f2",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 2
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27212</th>\n",
       "      <td>0.022450</td>\n",
       "      <td>0.951034</td>\n",
       "      <td>2.197333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>1.766731</td>\n",
       "      <td>0.007835</td>\n",
       "      <td>6.436602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0        f1        f2\n",
       "27212  0.022450  0.951034  2.197333\n",
       "7866   1.766731  0.007835  6.436602"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выборка features_train после масштабирования\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v1+json": {
       "is_truncated": false,
       "table": {
        "data": [
         {
          "f0": -0.5448279017,
          "f1": 1.390263717,
          "f2": -0.0949589272,
          "index": 27212
         },
         {
          "f0": 1.4559119028,
          "f1": -0.4804215411,
          "f2": 1.2095670795,
          "index": 7866
         }
        ],
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "f0",
           "type": "number"
          },
          {
           "name": "f1",
           "type": "number"
          },
          {
           "name": "f2",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 2
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27212</th>\n",
       "      <td>-0.544828</td>\n",
       "      <td>1.390264</td>\n",
       "      <td>-0.094959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>1.455912</td>\n",
       "      <td>-0.480422</td>\n",
       "      <td>1.209567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0        f1        f2\n",
       "27212 -0.544828  1.390264 -0.094959\n",
       "7866   1.455912 -0.480422  1.209567"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Выборка target_train до масштабирования\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27212    147.370612\n",
       "7866     147.630053\n",
       "Name: product, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выборка target_train после масштабирования\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27212    147.370612\n",
       "7866     147.630053\n",
       "Name: product, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Выборка features_valid до масштабирования\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v1+json": {
       "is_truncated": false,
       "table": {
        "data": [
         {
          "f0": 0.9489703127,
          "f1": -0.0575468844,
          "f2": 2.0957267062,
          "index": 71751
         },
         {
          "f0": 0.9929741327,
          "f1": 0.2066708998,
          "f2": -0.1422782909,
          "index": 80493
         }
        ],
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "f0",
           "type": "number"
          },
          {
           "name": "f1",
           "type": "number"
          },
          {
           "name": "f2",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 2
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71751</th>\n",
       "      <td>0.948970</td>\n",
       "      <td>-0.057547</td>\n",
       "      <td>2.095727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80493</th>\n",
       "      <td>0.992974</td>\n",
       "      <td>0.206671</td>\n",
       "      <td>-0.142278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0        f1        f2\n",
       "71751  0.948970 -0.057547  2.095727\n",
       "80493  0.992974  0.206671 -0.142278"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выборка features_valid после масштабирования\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v1+json": {
       "is_truncated": false,
       "table": {
        "data": [
         {
          "f0": 0.5179171653,
          "f1": -0.6100970829,
          "f2": -0.1262255036,
          "index": 71751
         },
         {
          "f0": 0.5683907714,
          "f1": -0.0860629171,
          "f2": -0.8149139766,
          "index": 80493
         }
        ],
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "f0",
           "type": "number"
          },
          {
           "name": "f1",
           "type": "number"
          },
          {
           "name": "f2",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 2
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71751</th>\n",
       "      <td>0.517917</td>\n",
       "      <td>-0.610097</td>\n",
       "      <td>-0.126226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80493</th>\n",
       "      <td>0.568391</td>\n",
       "      <td>-0.086063</td>\n",
       "      <td>-0.814914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0        f1        f2\n",
       "71751  0.517917 -0.610097 -0.126226\n",
       "80493  0.568391 -0.086063 -0.814914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Выборка target_valid до масштабирования\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71751     10.038645\n",
       "80493    114.551489\n",
       "Name: product, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выборка target_valid после масштабирования\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71751     10.038645\n",
       "80493    114.551489\n",
       "Name: product, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "for features in [\"features_train\", \"target_train\", \"features_valid\", \"target_valid\"]:\n",
    "    print(\"Выборка\", features, \"до масштабирования\")\n",
    "    display(data_split(geo_data_0)[features].head(2))\n",
    "    print(\"Выборка\", features, \"после масштабирования\")\n",
    "    display(data_scale(geo_data_0)[features].head(2))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30562e64-7606-4c3d-9c64-759ff18ee4dd",
   "metadata": {},
   "source": [
    "Как и планировалось происходит масштабирование признаков и не происходит масштабирование целевого признака."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a405eee-ae6f-4098-8be6-29e15d473166",
   "metadata": {},
   "source": [
    "- Найдем модели с наименьшим значением RMSE для выборок после масштабирования признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac475e1-b70e-4cc4-bf07-cac2f0b68027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель geo_data_scale_0 сохранена:\n",
      "models/geo_data_scale_0.joblib\n",
      "Модель geo_data_scale_1 сохранена:\n",
      "models/geo_data_scale_1.joblib\n",
      "Модель geo_data_scale_2 сохранена:\n",
      "models/geo_data_scale_2.joblib\n"
     ]
    }
   ],
   "source": [
    "for data, name in zip([geo_data_0, geo_data_1, geo_data_2], \n",
    "                      [\"geo_data_scale_0\", \"geo_data_scale_1\", \"geo_data_scale_2\"]):\n",
    "    \n",
    "    model_search(name, data_scale(data)[\"features_train\"],\n",
    "                       data_scale(data)[\"target_train\"],\n",
    "                       data_scale(data)[\"features_valid\"],\n",
    "                       data_scale(data)[\"target_valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76688d-87e0-4d25-ab24-88b5584c73c7",
   "metadata": {},
   "source": [
    "Выведем на экран параметры найденных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "246964b3-561d-4b86-9801-1e3f9e186398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель geo_data_scale_0\n",
      "Lasso(alpha=0.0001, max_iter=100000)\n",
      "Коэффициенты модели:\n",
      "[3.132, -7.108, 21.425]\n",
      " \n",
      "Модель geo_data_scale_1\n",
      "Lasso(alpha=0.001, max_iter=100000)\n",
      "Коэффициенты модели:\n",
      "[-1.299, -0.112, 45.885]\n",
      " \n",
      "Модель geo_data_scale_2\n",
      "Lasso(alpha=0.01, max_iter=100000)\n",
      "Коэффициенты модели:\n",
      "[0.044, -0.063, 19.81]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for model, name in zip([load(\"models/geo_data_scale_0.joblib\"), \n",
    "                        load(\"models/geo_data_scale_1.joblib\"), \n",
    "                        load(\"models/geo_data_scale_2.joblib\")],\n",
    "                       [\"geo_data_scale_0\", \"geo_data_scale_1\", \"geo_data_scale_2\"]):\n",
    "    \n",
    "    print(\"Модель {}\\n{}\\nКоэффициенты модели:\\n{}\\n{}\"\n",
    "          .format(name, \n",
    "                  model, \n",
    "                  list(np.round(model.coef_, 3)), \n",
    "                  \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a59d1c-6060-4758-81e7-587e14d81628",
   "metadata": {},
   "source": [
    "После масштабирования признаков параметры моделей заметно изменились. В частности, можно отметить увеличение коэффициента регуляризации для первого региона, что говорит о большем штрафе за использование высоких значений коэффициентов (f2) и повышении влияния f0 и f1 в этой модели. В модели для второго региона, наоборот, произошло снижение коэффициента alpha, что также привело к увеличению вляния признаков f0, f1. В модели для первого региона коэффициент регуляризации остался без изменения, но повысилось влияние признака f3 и снизилось влияние f2 на результаты предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87090211-5d68-4ef4-ab07-4211f9f1bc78",
   "metadata": {},
   "source": [
    "Выведем на экран RMSE моделей после масштабирования признаков (на валидационной выборке) и средний запас предсказанного сырья для кажого региона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f1a5019-f96e-49a0-9549-0893a6f86124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель geo_data_scale_0         \n",
      "RMSE модели на валидационной выборке: 37.579421         \n",
      "Средний запас предсказанного сырья: 92.592570         \n",
      " \n",
      "Модель geo_data_scale_1         \n",
      "RMSE модели на валидационной выборке: 0.893093         \n",
      "Средний запас предсказанного сырья: 68.728547         \n",
      " \n",
      "Модель geo_data_scale_2         \n",
      "RMSE модели на валидационной выборке: 40.029692         \n",
      "Средний запас предсказанного сырья: 94.965209         \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for data, name in zip([geo_data_0, geo_data_1, geo_data_2], \n",
    "                      [\"geo_data_scale_0\", \"geo_data_scale_1\", \"geo_data_scale_2\"]):\n",
    "    \n",
    "    print(\"Модель {}\\\n",
    "         \\nRMSE модели на валидационной выборке: {:.6f}\\\n",
    "         \\nСредний запас предсказанного сырья: {:.6f}\\\n",
    "         \\n{}\".\n",
    "         format(name,\n",
    "                rmse_calc(data, name, scale=True)[\"rmse\"],\n",
    "                rmse_calc(data, name, scale=True)[\"mean_predict\"],\n",
    "                \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6f847-d151-4a2f-824d-2508c892f0b6",
   "metadata": {},
   "source": [
    "Можно видеть, что масштабирование признаков не привело к улучшению метрик модели, кроме того значения RMSE и среднего запаса сырья совпадают вплоть до 6 знака после запятой. Это говорит о пределе возможностей линейной модели и эффективности L1-регуляризации на исходных данных. Дальнейшую работу для удобства будем проводить на данных без масштабирования.\n",
    "\n",
    "- Сохраним предсказания и правильные ответы на валидационной выборке.\n",
    "- Изменим тип предсказанных данных с np.array на pd.Series и присвоим им индексы такие же как у целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e811afec-bfed-432c-9628-3257f8b6c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_valid_geo_data_0 = data_split(geo_data_0)[\"target_valid\"]\n",
    "predict_valid_geo_data_0 = load(\"models/geo_data_0.joblib\")\\\n",
    "                           .predict(data_split(geo_data_0)[\"features_valid\"])\n",
    "predict_valid_geo_data_0 = pd.Series(predict_valid_geo_data_0)\n",
    "predict_valid_geo_data_0.index = target_valid_geo_data_0.index\n",
    "\n",
    "target_valid_geo_data_1 = data_split(geo_data_1)[\"target_valid\"]\n",
    "predict_valid_geo_data_1 = load(\"models/geo_data_1.joblib\")\\\n",
    "                           .predict(data_split(geo_data_1)[\"features_valid\"])\n",
    "predict_valid_geo_data_1 = pd.Series(predict_valid_geo_data_1)\n",
    "predict_valid_geo_data_1.index = target_valid_geo_data_1.index\n",
    "\n",
    "target_valid_geo_data_2 = data_split(geo_data_2)[\"target_valid\"]\n",
    "predict_valid_geo_data_2 = load(\"models/geo_data_2.joblib\")\\\n",
    "                           .predict(data_split(geo_data_2)[\"features_valid\"])\n",
    "predict_valid_geo_data_2 = pd.Series(predict_valid_geo_data_2)\n",
    "predict_valid_geo_data_2.index = target_valid_geo_data_2.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24681719-aaaf-447a-adfc-b184dd1ec2c7",
   "metadata": {},
   "source": [
    "С помощью sweetviz проанализируем как изменяется величина остатков (predict - target) для каждого региона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d35015-06e2-4110-8ad7-bd50d00262b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_geo_data_0 = data_split(geo_data_0)[\"features_valid\"]\n",
    "valid_geo_data_0[\"difference\"] = predict_valid_geo_data_0 - target_valid_geo_data_0\n",
    "\n",
    "report_valid_0 = sv.analyze([valid_geo_data_0, \"valid_geo_data_0\"], \n",
    "                            target_feat=\"difference\")\n",
    "report_valid_0.show_html(\"sweetviz/valid_geo_data_0.html\")\n",
    "report_valid_0.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02949f-2111-45db-b7d5-f934076b1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_geo_data_1 = data_split(geo_data_1)[\"features_valid\"]\n",
    "valid_geo_data_1[\"difference\"] = predict_valid_geo_data_1 - target_valid_geo_data_1\n",
    "\n",
    "report_valid_1 = sv.analyze([valid_geo_data_1, \"valid_geo_data_1\"], \n",
    "                            target_feat=\"difference\")\n",
    "report_valid_1.show_html(\"sweetviz/valid_geo_data_1.html\")\n",
    "report_valid_1.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a186e-7734-4bb4-b285-de29bc5551b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_geo_data_2 = data_split(geo_data_2)[\"features_valid\"]\n",
    "valid_geo_data_2[\"difference\"] = predict_valid_geo_data_2 - target_valid_geo_data_2\n",
    "\n",
    "report_valid_2 = sv.analyze([valid_geo_data_2, \"valid_geo_data_2\"], \n",
    "                            target_feat=\"difference\")\n",
    "report_valid_2.show_html(\"sweetviz/valid_geo_data_2.html\")\n",
    "report_valid_2.show_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb10d39-da73-442f-8999-d295653a7985",
   "metadata": {},
   "source": [
    "Результаты показывают, что остатки во всех трех регионах распределены по нормальному закону. Их минимальный размах в регионе 1, намного больший в регионах 0 и 2, что согласуется с найденными ранее величинами RMSE. Интересно отметить, что наибольшая абсолютная величина разности между предсказанными и истинными значениями в регионе 0 наблюдается при экстремальных значениях признака f2, причем модель завышает результаты при максимальных значениях признака и занижает при минимальных. В регионе 2 наибольшая абсолютная величина остатков наблюдается при экстремальных значениях всех трех признаков. Причем для признаков f0, f1 наблюдаются заниженные предсказанные величины, а для признака f2 также как и в регионе 0 наблюдается завышение результатов при максимальных значениях признака f2 и занижение при минимальных. Можно заключить, что найденные модели машинного обучения, для некоторых комбинаций признаков, будут завышать величину запасов предсказанного сырья."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f356f",
   "metadata": {},
   "source": [
    "## Подготовка к расчёту прибыли"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df75004-4e5e-462b-bc3e-12078b8cb71f",
   "metadata": {},
   "source": [
    "- Сохраним все ключевые значения для расчётов в отдельных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "777724de-ca69-43ff-aca8-9f08b65b9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество лучших скважин, выбранных с помощью машинного обучения\n",
    "BEST_NUM = 200\n",
    "# бюджет на разработку скважин в регионе\n",
    "BUDGET_REGION = 10e9\n",
    "# доход с каждой единицы продукта\n",
    "INCOME_UNIT = 450e3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e802b06-2b7b-4f54-8df9-636e7822dfc4",
   "metadata": {},
   "source": [
    "- Рассчитаем достаточный объём сырья для безубыточной разработки новой скважины. Сравним полученный объём сырья со средним запасом в каждом регионе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f074f8f0-ea52-48fb-8e50-e2aea3dc2d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний объем сырья для безубыточной разработки:\n",
      "111.1\n"
     ]
    }
   ],
   "source": [
    "required_volume = BUDGET_REGION / (BEST_NUM * INCOME_UNIT)\n",
    "print(\"Средний объем сырья для безубыточной разработки:\", \n",
    "      round(required_volume, 1), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747e4c5-44bc-4bb8-813b-a51b9a439b37",
   "metadata": {
    "tags": []
   },
   "source": [
    "Можно видеть, что при заданных ценах на баррель сырья и бюджете на разработку скважин в регионе средний объем сырья для 200 скважин должен составлять 111 баррелей. Это заметно больше среднего содержания сырья для исследуемых регионов, в которых данная величина составляет от 68 (регион 1) до 95 (регионы 0 и 2) баррелей. По этой причине для разработки необходимо выбирать скважины с максимальным запасом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a9147-209a-4d73-a0a2-364c4d5dcd97",
   "metadata": {},
   "source": [
    "- Напишем функцию для расчёта прибыли по выбранным скважинам и предсказаниям модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c4b274a-52e3-4e72-b65c-f295069f7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit_calc(true, predict, best_num=BEST_NUM, \n",
    "                               income_unit=INCOME_UNIT, \n",
    "                               budget_region=BUDGET_REGION):\n",
    "    \"\"\"\n",
    "    Функция примает на вход Series с истинными и предсказанными\n",
    "    значениями прибыли (требуется совпадение индексов), \n",
    "    количество лучших анализируемых скважин, доход с каждой единицы \n",
    "    продукта, бюджет на разработку скважин в регионе.\n",
    "    Выбирает скважины с максимальными значениями предсказаний, \n",
    "    суммирует целевое значение объема сырья, соответствующее этим \n",
    "    предсказаниям.\n",
    "    Выводит прибыль для полученного объема сырья.\n",
    "    \"\"\"\n",
    "    if len(predict) >= best_num:\n",
    "        predict = predict.sort_values(ascending=False).iloc[:best_num]\n",
    "        true = true[predict.index]\n",
    "        revenue = true.sum() * income_unit\n",
    "        profit = revenue - budget_region\n",
    "        return profit\n",
    "    else:\n",
    "        print(\"Ошибка! Размер выборки меньше необходимого\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a9b6a",
   "metadata": {},
   "source": [
    "## Расчёт прибыли и рисков "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbfdba4-3c28-42b4-9bc6-bc78a584f259",
   "metadata": {},
   "source": [
    "- Применим технику Bootstrap с 1000 выборок и объемом каждой выборки в 500 единиц, чтобы найти распределение прибыли. Выборки будем создавать без возвращения значений, т.к. при разработке региона исследуется 500 разных точек. \n",
    "- Найдем среднюю прибыль, 95%-й доверительный интервал и риск убытков (отрицательной прибыли)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d7d0d25-c5e8-4fc7-9c41-e6396f05a7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Регион geo_data_0         \n",
      "Средняя прибыль: 380710890.7         \n",
      "95.0 %-й доверительный интервал: [-126947638.0, 879613967.8]         \n",
      "Риск убытков: 7.2%\n",
      "Регион geo_data_1         \n",
      "Средняя прибыль: 454785434.8         \n",
      "95.0 %-й доверительный интервал: [46730084.8, 840213356.3]         \n",
      "Риск убытков: 1.3%\n",
      "Регион geo_data_2         \n",
      "Средняя прибыль: 388916252.1         \n",
      "95.0 %-й доверительный интервал: [-115609565.8, 905292904.4]         \n",
      "Риск убытков: 7.3%\n"
     ]
    }
   ],
   "source": [
    "# количество выборок\n",
    "bootstrap_number = 1000\n",
    "# объем каждой выборки в единицах\n",
    "bootstrap_volume = 500\n",
    "# доверительный интервал для средней прибыли\n",
    "quantile_bottom = 0.025\n",
    "quantile_upper = 0.975\n",
    "\n",
    "# списки для хранения величины прибыли\n",
    "profit_list_geo_data_0 = list()\n",
    "profit_list_geo_data_1 = list()\n",
    "profit_list_geo_data_2 = list()\n",
    "\n",
    "# проведем Bootstrap\n",
    "state = np.random.RandomState(12345)\n",
    "for predict_valid,\\\n",
    "    target_valid, profit_list in zip([predict_valid_geo_data_0, \n",
    "                                      predict_valid_geo_data_1, \n",
    "                                      predict_valid_geo_data_2], \n",
    "                                     [target_valid_geo_data_0, \n",
    "                                      target_valid_geo_data_1, \n",
    "                                      target_valid_geo_data_2],\n",
    "                                     [profit_list_geo_data_0,\n",
    "                                      profit_list_geo_data_1,\n",
    "                                      profit_list_geo_data_2]):\n",
    "    \n",
    "    for _ in range(bootstrap_number):\n",
    "        bootstrap_predict = predict_valid.sample(n=bootstrap_volume, replace=False, \n",
    "                                                 random_state=state)\n",
    "        \n",
    "        predict = bootstrap_predict\n",
    "        true = target_valid[predict.index]\n",
    "        \n",
    "        profit = profit_calc(true, predict)\n",
    "        profit_list.append(profit)\n",
    "\n",
    "# расчитаем величину прибыли\n",
    "for profit_list, region in zip([profit_list_geo_data_0,\n",
    "                                profit_list_geo_data_1,\n",
    "                                profit_list_geo_data_2],\n",
    "                               [\"geo_data_0\", \"geo_data_1\", \"geo_data_2\"]):\n",
    "    print(\"Регион {}\\\n",
    "         \\nСредняя прибыль: {:.1f}\\\n",
    "         \\n{} %-й доверительный интервал: [{:.1f}, {:.1f}]\\\n",
    "         \\nРиск убытков: {:.1f}%\"\n",
    "    .format(region,\n",
    "    # средняя прибыль        \n",
    "            pd.Series(profit_list).mean(),\n",
    "    # доверительный интервал\n",
    "            (quantile_upper - quantile_bottom) * 100, \n",
    "            pd.Series(profit_list).quantile(quantile_bottom),\n",
    "            pd.Series(profit_list).quantile(quantile_upper),\n",
    "    # риск убытков\n",
    "            ((pd.Series(profit_list) < 0).sum() / \n",
    "             len(pd.Series(profit_list_geo_data_0))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397771bf-2253-4432-a529-75daa537cf49",
   "metadata": {},
   "source": [
    "Условие по допустимой вероятности убытков (ниже 2,5 %) проходит только регион geo_data_1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c9d87-98cc-4c74-8e36-824590680d46",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "Можно заключить, что наиболее удачным регионом для разработки скважин является geo_data_1. Этот регион обладает наиболее предсказуемыми запасами сырья, которые удается определить с наибольшей точностью, используя линейную модель. В нем наблюдается одновременно наименьший риск убытков и наибольшее значение средней прибыли. Найденный доверительный интервал для этого региона показывает, что с вероятностью 95% можно получить ненулевую прибыль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6def596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
