{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, notebook\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "SCORE = \"f1\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: (159292, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./toxic_comments.csv\", index_col=[0])\n",
    "\n",
    "display(df.head())\n",
    "print(f\"Размер датасета: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим и лемматизируем текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAR_LEMMATIZE = False\n",
    "if CLEAR_LEMMATIZE:\n",
    "    def clear_text(text):\n",
    "        text_clear = re.sub(r\"[^a-zA-Z' ]\", \" \", text)\n",
    "        text_clear = text_clear.split()\n",
    "        text_clear = ' '.join(text_clear)\n",
    "\n",
    "        return text_clear.lower()\n",
    "\n",
    "    X_clear = df[\"text\"].apply(clear_text)\n",
    "\n",
    "    def lemmatize(text):\n",
    "        spacy.prefer_gpu()\n",
    "        nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "        token_list = nlp(text)\n",
    "        text_lemm = \" \".join([token.lemma_ for token in token_list])\n",
    "\n",
    "        return text_lemm\n",
    "\n",
    "    tqdm.pandas()\n",
    "    X_lemm = X_clear.progress_apply(lemmatize)\n",
    "    X_lemm.to_csv(\"./toxic_comments_lemm_1.csv\", index=False)\n",
    "    \n",
    "    print(\"Файл сохранен\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка для скачивания датасета после лемматизации:\n",
    "\n",
    "https://drive.google.com/file/d/1Lj-z9_GUS474aCsk8dHuOQ_HcggwL6Dk/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww he match this background colour I be see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man I be really not try to edit war it be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more I can not make any real suggestion on imp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edit make under my usernam...      0\n",
       "1  d'aww he match this background colour I be see...      0\n",
       "2  hey man I be really not try to edit war it be ...      0\n",
       "3  more I can not make any real suggestion on imp...      0\n",
       "4  you sir be my hero any chance you remember wha...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета после лемматизации: (159282, 2)\n"
     ]
    }
   ],
   "source": [
    "X_lemm = pd.read_csv(\"./toxic_comments_lemm.csv\")\n",
    "X_lemm.index = df.index\n",
    "X_lemm[\"toxic\"] = df[\"toxic\"]\n",
    "X_lemm = X_lemm.dropna()\n",
    "\n",
    "display(X_lemm.head())\n",
    "print(f\"Размер датасета после лемматизации: {X_lemm.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тестовую и обучающую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающего датасета: (143353,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lemm[\"text\"], X_lemm[\"toxic\"], test_size=0.1, random_state=SEED)\n",
    "\n",
    "sw = stopwords.words(\"english\")\n",
    "tfidf = TfidfVectorizer(stop_words=sw, ngram_range=(1,1), max_df=0.95)\n",
    "\n",
    "print(f\"Размер обучающего датасета: {X_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_HP_LR_TFIDF = False\n",
    "if SEARCH_HP_LR_TFIDF:\n",
    "    pipe_lr_tfidf = Pipeline([(\"vector_tfidf\", tfidf),\n",
    "                              (\"lr_tfidf\", LogisticRegression(max_iter=10000,\n",
    "                                                              solver=\"saga\"))])\n",
    "    \n",
    "    params_lr_tfidf = {\"lr_tfidf__penalty\": [\"l2\", \"l1\"],\n",
    "                       \"lr_tfidf__C\": [1, 5, 10, 15],\n",
    "                       \"lr_tfidf__fit_intercept\": [True, False]}\n",
    "\n",
    "    grid_lr_tfidf = RandomizedSearchCV(estimator=pipe_lr_tfidf,\n",
    "                                       param_distributions=params_lr_tfidf,\n",
    "                                       scoring=SCORE,\n",
    "                                       cv=5,\n",
    "                                       n_iter=16,\n",
    "                                       random_state=SEED,\n",
    "                                       n_jobs=-1,\n",
    "                                       verbose=2)\n",
    "\n",
    "    grid_lr_tfidf.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"params_lr_tfidf = {grid_lr_tfidf.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с лучшими параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Логистическая регрессия (TF-IDF)\n",
      "f1_score_lr_tfidf = 0.783\n"
     ]
    }
   ],
   "source": [
    "pipe_lr_tfidf = Pipeline([(\"vector_tfidf\", tfidf),\n",
    "                          (\"lr_tfidf\", LogisticRegression(max_iter=10000,\n",
    "                                                          solver=\"saga\"))])\n",
    "\n",
    "params_lr_tfidf = {'lr_tfidf__penalty': ['l1'], \n",
    "                   'lr_tfidf__fit_intercept': [True], \n",
    "                   'lr_tfidf__C': [5]}\n",
    "\n",
    "grid_lr_tfidf = RandomizedSearchCV(estimator=pipe_lr_tfidf,\n",
    "                                   param_distributions=params_lr_tfidf,\n",
    "                                   scoring=SCORE,\n",
    "                                   cv=5,\n",
    "                                   n_iter=1,\n",
    "                                   random_state=SEED,\n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=2)\n",
    "\n",
    "grid_lr_tfidf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Логистическая регрессия (TF-IDF)\\n\"\n",
    "      f\"f1_score_lr_tfidf = {grid_lr_tfidf.best_score_:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем текст в токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 159292/159292 [00:36<00:00, 4385.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета после токенизации: (159292, 256)\n",
      "[[ 101 7526 2339 ...    0    0    0]\n",
      " [ 101 1040 1005 ...    0    0    0]\n",
      " [ 101 4931 2158 ...    0    0    0]\n",
      " [ 101 1000 2062 ...    0    0    0]\n",
      " [ 101 2017 1010 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"unitary/toxic-bert\")\n",
    "tokenized = df[\"text\"].progress_apply(lambda x: tokenizer.encode(x,\n",
    "                                                        add_special_tokens=True,\n",
    "                                                        max_length=256,\n",
    "                                                        truncation=True))\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "print(f\"Размер датасета после токенизации: {padded.shape}\")\n",
    "print(padded[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc64fb572194a2ba55326ea25dac773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета после поиска эмбеддингов: (159292, 768)\n",
      "[[-0.5585107  -1.0476651   0.7199489  ... -0.71159047  0.5249052\n",
      "   0.1127703 ]\n",
      " [-0.59337103 -0.9981305   0.6239386  ... -0.69221896  0.4633578\n",
      "   0.10821168]\n",
      " [-0.61220884 -0.8657579   0.7485891  ... -0.6126195   0.5090271\n",
      "   0.13732637]\n",
      " [-0.5692074  -0.92946845  0.589398   ... -0.70434874  0.3813434\n",
      "   0.1057018 ]\n",
      " [-0.79451674 -0.84589386  0.889402   ... -0.7354617   0.6126284\n",
      "  -0.06679608]]\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModel.from_pretrained(\"unitary/toxic-bert\").to(DEVICE)\n",
    "\n",
    "batch_size = 400\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size + 1)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i + 1)]).to(DEVICE)\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i + 1)]).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].to('cpu').numpy())\n",
    "        del batch_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "features = np.concatenate(embeddings)\n",
    "\n",
    "print(f\"Размер датасета после поиска эмбеддингов: {features.shape}\")\n",
    "print(features[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим найденные эмбеддинги на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(features, \n",
    "                                                                        df[\"toxic\"], \n",
    "                                                                        test_size=0.1, \n",
    "                                                                        random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.4min remaining:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_lr_bert = 0.944\n"
     ]
    }
   ],
   "source": [
    "params_lr_bert = {\"penalty\": \"l1\",\n",
    "                  \"C\": 5,\n",
    "                  \"fit_intercept\": True}\n",
    "\n",
    "lr_bert = LogisticRegression(**params_lr_bert, max_iter=10000, solver=\"saga\")\n",
    "\n",
    "f1_score_lr_bert = cross_val_score(lr_bert, X_train_bert, y_train_bert, \n",
    "                                   scoring=SCORE, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "print(f\"f1_score_lr_bert = {np.mean(f1_score_lr_bert):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 50.9min remaining: 33.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 51.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_gb_bert = 0.943\n"
     ]
    }
   ],
   "source": [
    "params_gb_bert = {'n_estimators': 100,\n",
    "                  'max_depth': 3,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "gb_bert = GradientBoostingClassifier(**params_gb_bert, random_state=SEED)\n",
    "\n",
    "f1_score_gb_bert = cross_val_score(gb_bert, X_train_bert, y_train_bert, \n",
    "                                   scoring=SCORE, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "print(f\"f1_score_gb_bert = {np.mean(f1_score_gb_bert):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним метрики полученных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr_bert</th>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb_bert</th>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_tfidf</th>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1_score\n",
       "models            \n",
       "lr_bert      0.944\n",
       "gb_bert      0.943\n",
       "lr_tfidf     0.783"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data={\"f1_score\": [grid_lr_tfidf.best_score_,\n",
    "                                          np.mean(f1_score_lr_bert),\n",
    "                                          np.mean(f1_score_gb_bert)]},\n",
    "                       index=pd.Index(data=[\"lr_tfidf\", \"lr_bert\", \"gb_bert\"], name=\"models\"))\\\n",
    "            .sort_values(\"f1_score\", ascending=False).round(3)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наибольшей величиной метрики обладает логистическая регрессия, построенная на эмбеддингах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем величину метрики лучшей модели на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_lr_bert_test = 0.949\n"
     ]
    }
   ],
   "source": [
    "lr_bert.fit(X_train_bert, y_train_bert)\n",
    "y_predict = lr_bert.predict(X_test_bert)\n",
    "\n",
    "print(f\"f1_score_lr_bert_test = {f1_score(y_test_bert, y_predict):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найденная величина метрики удовлетворяет условиям задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В работе проанализированы модели классификации текста комментариев на данных после TF-IDF и выделения эмбеддиногов. Показано, что наибольшей величиной метрики обладает логистическая регрессия, построенная на данных после выделения эмбеддиногов с помощью предварительно обученной модели BERT. Величина метрики F1 на тестовой выборке равна 0.95 и с запасом удовлетворяет условиям задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 9147,
    "start_time": "2022-12-05T06:17:09.752Z"
   },
   {
    "duration": 3,
    "start_time": "2022-12-05T06:17:26.943Z"
   },
   {
    "duration": 352,
    "start_time": "2022-12-05T06:17:31.775Z"
   },
   {
    "duration": 67,
    "start_time": "2022-12-05T06:17:39.255Z"
   },
   {
    "duration": 56,
    "start_time": "2022-12-05T06:17:57.076Z"
   },
   {
    "duration": 60,
    "start_time": "2022-12-05T06:18:04.977Z"
   },
   {
    "duration": 3701,
    "start_time": "2022-12-05T06:18:33.580Z"
   },
   {
    "duration": 4800,
    "start_time": "2022-12-05T06:37:03.147Z"
   },
   {
    "duration": 3,
    "start_time": "2022-12-05T06:37:15.567Z"
   },
   {
    "duration": 766,
    "start_time": "2022-12-05T06:37:18.569Z"
   },
   {
    "duration": 45178,
    "start_time": "2022-12-05T06:37:23.003Z"
   },
   {
    "duration": 8,
    "start_time": "2022-12-05T06:40:32.997Z"
   },
   {
    "duration": 4,
    "start_time": "2022-12-05T06:40:44.445Z"
   },
   {
    "duration": 346,
    "start_time": "2022-12-05T06:40:55.508Z"
   },
   {
    "duration": 4,
    "start_time": "2022-12-05T06:41:51.884Z"
   },
   {
    "duration": 20,
    "start_time": "2022-12-05T06:41:59.517Z"
   },
   {
    "duration": 2618,
    "start_time": "2022-12-05T06:42:29.224Z"
   },
   {
    "duration": 42,
    "start_time": "2022-12-05T06:43:41.961Z"
   },
   {
    "duration": 394,
    "start_time": "2022-12-05T06:44:51.959Z"
   },
   {
    "duration": 9027,
    "start_time": "2022-12-05T06:47:46.376Z"
   },
   {
    "duration": 110564,
    "start_time": "2022-12-05T06:48:04.616Z"
   },
   {
    "duration": 4,
    "start_time": "2022-12-05T07:17:22.484Z"
   },
   {
    "duration": 85,
    "start_time": "2022-12-05T07:17:29.436Z"
   },
   {
    "duration": 84,
    "start_time": "2022-12-05T07:18:18.809Z"
   },
   {
    "duration": 19650,
    "start_time": "2022-12-05T07:18:56.945Z"
   },
   {
    "duration": 19925,
    "start_time": "2022-12-05T07:20:07.656Z"
   },
   {
    "duration": 2827,
    "start_time": "2022-12-05T07:21:36.134Z"
   },
   {
    "duration": 10,
    "start_time": "2022-12-05T07:21:57.320Z"
   },
   {
    "duration": 6494,
    "start_time": "2022-12-05T07:22:13.888Z"
   },
   {
    "duration": 5,
    "start_time": "2022-12-05T07:23:58.486Z"
   },
   {
    "duration": 5,
    "start_time": "2022-12-05T07:24:20.034Z"
   },
   {
    "duration": 2804,
    "start_time": "2022-12-05T07:25:23.142Z"
   },
   {
    "duration": 393,
    "start_time": "2022-12-05T07:26:49.594Z"
   },
   {
    "duration": 75,
    "start_time": "2022-12-05T07:34:35.617Z"
   },
   {
    "duration": 74,
    "start_time": "2022-12-05T07:34:44.539Z"
   },
   {
    "duration": 1847,
    "start_time": "2022-12-05T07:34:57.268Z"
   },
   {
    "duration": 78,
    "start_time": "2022-12-05T07:35:53.829Z"
   },
   {
    "duration": 74,
    "start_time": "2022-12-05T07:36:02.330Z"
   },
   {
    "duration": 2,
    "start_time": "2022-12-05T07:36:17.909Z"
   },
   {
    "duration": 81,
    "start_time": "2022-12-05T07:44:20.005Z"
   },
   {
    "duration": 18,
    "start_time": "2022-12-05T07:44:26.615Z"
   },
   {
    "duration": 4,
    "start_time": "2022-12-05T07:52:26.928Z"
   },
   {
    "duration": 4830,
    "start_time": "2022-12-05T07:52:26.939Z"
   },
   {
    "duration": 3,
    "start_time": "2022-12-05T07:52:31.770Z"
   },
   {
    "duration": 8,
    "start_time": "2022-12-05T07:52:31.774Z"
   },
   {
    "duration": 728,
    "start_time": "2022-12-05T07:52:31.783Z"
   },
   {
    "duration": 14304,
    "start_time": "2022-12-05T07:52:32.514Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.820Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.821Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.823Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.824Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.825Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.826Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.827Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.828Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.829Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:52:46.830Z"
   },
   {
    "duration": 3,
    "start_time": "2022-12-05T07:53:28.779Z"
   },
   {
    "duration": 4857,
    "start_time": "2022-12-05T07:53:28.784Z"
   },
   {
    "duration": 3,
    "start_time": "2022-12-05T07:53:33.642Z"
   },
   {
    "duration": 22,
    "start_time": "2022-12-05T07:53:33.646Z"
   },
   {
    "duration": 783,
    "start_time": "2022-12-05T07:53:33.670Z"
   },
   {
    "duration": 304981,
    "start_time": "2022-12-05T07:53:34.455Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.439Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.441Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.442Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.444Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.445Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.447Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.448Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.450Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.451Z"
   },
   {
    "duration": 0,
    "start_time": "2022-12-05T07:58:39.452Z"
   },
   {
    "duration": 4,
    "start_time": "2022-12-05T07:58:56.775Z"
   },
   {
    "duration": 5067,
    "start_time": "2022-12-05T07:58:56.782Z"
   },
   {
    "duration": 2,
    "start_time": "2022-12-05T07:59:01.851Z"
   },
   {
    "duration": 9,
    "start_time": "2022-12-05T07:59:01.855Z"
   },
   {
    "duration": 764,
    "start_time": "2022-12-05T07:59:01.866Z"
   },
   {
    "duration": 93155,
    "start_time": "2022-12-05T07:59:02.631Z"
   },
   {
    "duration": 8,
    "start_time": "2022-12-05T08:00:35.789Z"
   },
   {
    "duration": 5786,
    "start_time": "2022-12-05T08:00:35.799Z"
   },
   {
    "duration": 971,
    "start_time": "2022-12-05T08:00:41.587Z"
   },
   {
    "duration": 6202,
    "start_time": "2022-12-05T08:00:42.559Z"
   },
   {
    "duration": 188159,
    "start_time": "2022-12-05T08:00:48.764Z"
   },
   {
    "duration": 17,
    "start_time": "2022-12-05T08:03:56.925Z"
   },
   {
    "duration": 38534,
    "start_time": "2022-12-05T08:03:56.945Z"
   },
   {
    "duration": 6686,
    "start_time": "2022-12-05T08:04:35.486Z"
   },
   {
    "duration": 11,
    "start_time": "2022-12-05T08:04:42.173Z"
   },
   {
    "duration": 8930,
    "start_time": "2022-12-05T08:04:42.186Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
